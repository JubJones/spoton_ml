parent_run_name: "mtmmc_reid_comparison_query_gallery_v3"

mlflow:
  experiment_name: "Re-ID Models Comparison - Query/Gallery"

environment:
  device: "auto" # Options: "auto", "cuda:0", "mps", "cpu"
  seed: 42

data:
  base_path: "D:/MTMMC" # Adjust to your MTMMC dataset path
  # base_path: "/Volumes/HDD/MTMMC"
  weights_base_dir: "weights/reid"

  # --- Evaluation Split ---
  split_type: "val" # Options: "train", "val"

  # --- Environment / Scene Selection ---
  selected_environment: "factory" # Options: "factory", "campus"

  # --- Scene Specific Settings ---
  campus:
    scene_id: "s37"
    scene_annotation_file: "s37.json" # JSON file for this scene in data.base_path/split/data.split_type/
    camera_ids: ["c01", "c02", "c03", "c05"]
    frame_sample_rate: 5
    max_crops_per_id_per_cam: -1
    query_cameras: ["c01", "c03"]
    gallery_cameras: ["c02", "c05"]

  factory:
    scene_id: "s14"
    scene_annotation_file: "s14.json" # JSON file for this scene in data.base_path/split/data.split_type/
    camera_ids: ["c09", "c12", "c13", "c16"]
    frame_sample_rate: 5
    max_crops_per_id_per_cam: -1
    query_cameras: ["c09", "c12"]
    gallery_cameras: ["c13", "c16"]

evaluation:
  distance_metric: "cosine" # "cosine" or "euclidean"

# --- Re-ID Models to Run (as Child Runs) ---
models_to_run:
  - model: { model_type: "resnet50", weights_path: "resnet50_fc512_msmt17.pt", input_size: [256, 128], feature_dim: 512 }
  - model: { model_type: "resnet50", weights_path: "resnet50_fc512_market1501.pt", input_size: [256, 128], feature_dim: 512 }
  - model: { model_type: "mlfn", weights_path: "mlfn_market1501.pt", input_size: [256, 128], feature_dim: 512 }
  - model: { model_type: "mlfn", weights_path: "mlfn_dukemtmcreid.pt", input_size: [256, 128], feature_dim: 512 }
  - model: { model_type: "hacnn", weights_path: "hacnn_market1501.pt", input_size: [160, 64], feature_dim: 512 }
  - model: { model_type: "hacnn", weights_path: "hacnn_dukemtmcreid.pt", input_size: [160, 64], feature_dim: 512 }
  - model: { model_type: "mobilenetv2_x1_4", weights_path: "mobilenetv2_x1_4_market1501.pt", input_size: [256, 128], feature_dim: 1792 }
  - model: { model_type: "mobilenetv2_x1_4", weights_path: "mobilenetv2_x1_4_dukemtmcreid.pt", input_size: [256, 128], feature_dim: 1792 }
  - model: { model_type: "osnet_x1_0", weights_path: "osnet_x1_0_msmt17.pt", input_size: [256, 128], feature_dim: 512 }
  - model: { model_type: "osnet_ain_x1_0", weights_path: "osnet_ain_x1_0_msmt17.pt", input_size: [256, 128], feature_dim: 512 }
  - model: { model_type: "osnet_ibn_x1_0", weights_path: "osnet_ibn_x1_0_msmt17.pt", input_size: [256, 128], feature_dim: 512 }
  - model: { model_type: "lmbn_n", weights_path: "lmbn_n_duke.pt", input_size: [256, 128], feature_dim: 512 }
  - model: { model_type: "lmbn_n", weights_path: "lmbn_n_market.pt", input_size: [256, 128], feature_dim: 512 }
  - model: { model_type: "clip", weights_path: "clip_market1501.pt", input_size: [224, 224], feature_dim: 512 }
  - model: { model_type: "clip", weights_path: "clip_duke.pt", input_size: [224, 224], feature_dim: 512 }